{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Main Recommender System Pipeline\n",
                "\n",
                "This notebook orchestrates the complete recommender system workflow, from data loading to generating final recommendations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "print(\"Environment setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading and Preprocessing\n",
                "\n",
                "Run the data preprocessing pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import preprocessing functions\n",
                "# %run data_preprocessing.ipynb\n",
                "\n",
                "# Or manually load processed data\n",
                "# user_item_matrix = pd.read_csv('../results/user_item_matrix.csv', index_col=0)\n",
                "# print(f\"Loaded user-item matrix: {user_item_matrix.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Build Collaborative Filtering Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load or compute collaborative filtering\n",
                "# %run collaborative.ipynb\n",
                "\n",
                "# Or load precomputed similarities\n",
                "# user_similarity = pd.read_csv('../results/user_similarity.csv', index_col=0)\n",
                "# item_similarity_cf = pd.read_csv('../results/item_similarity.csv', index_col=0)\n",
                "# print(\"Collaborative filtering models loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build Content-Based Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load or compute content-based filtering\n",
                "# %run content_based.ipynb\n",
                "\n",
                "# Or load precomputed models\n",
                "# item_similarity_content = pd.read_csv('../results/content_item_similarity.csv', index_col=0)\n",
                "# print(\"Content-based model loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Generate Recommendations for Target Users"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define target users\n",
                "# target_users = user_item_matrix.index[:10]  # First 10 users as example\n",
                "\n",
                "# Generate recommendations using different methods\n",
                "# all_recommendations = {}\n",
                "\n",
                "# for user_id in target_users:\n",
                "#     all_recommendations[user_id] = {\n",
                "#         'collaborative': get_user_recommendations(user_id, user_item_matrix, user_similarity),\n",
                "#         'content_based': get_user_profile_recommendations(user_id, user_item_matrix, item_similarity_content, items),\n",
                "#         'hybrid': weighted_hybrid_recommendations(user_id, collaborative_recs, content_recs)\n",
                "#     }\n",
                "\n",
                "# print(f\"Generated recommendations for {len(target_users)} users\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Display Sample Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display recommendations for a sample user\n",
                "# sample_user = target_users[0]\n",
                "\n",
                "# print(f\"\\n{'='*80}\")\n",
                "# print(f\"RECOMMENDATIONS FOR USER: {sample_user}\")\n",
                "# print(f\"{'='*80}\\n\")\n",
                "\n",
                "# print(\"Collaborative Filtering:\")\n",
                "# print(all_recommendations[sample_user]['collaborative'].head())\n",
                "\n",
                "# print(\"\\nContent-Based:\")\n",
                "# print(all_recommendations[sample_user]['content_based'].head())\n",
                "\n",
                "# print(\"\\nHybrid:\")\n",
                "# print(all_recommendations[sample_user]['hybrid'].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate Recommendation Quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
                "\n",
                "# Split data for evaluation\n",
                "# train_data, test_data = train_test_split(ratings_clean, test_size=0.2, random_state=42)\n",
                "\n",
                "# Calculate metrics\n",
                "# def calculate_metrics(predictions, actuals):\n",
                "#     mae = mean_absolute_error(actuals, predictions)\n",
                "#     rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
                "#     return {'MAE': mae, 'RMSE': rmse}\n",
                "\n",
                "# evaluation_results = {\n",
                "#     'collaborative': calculate_metrics(...),\n",
                "#     'content_based': calculate_metrics(...),\n",
                "#     'hybrid': calculate_metrics(...)\n",
                "# }\n",
                "\n",
                "# results_df = pd.DataFrame(evaluation_results).T\n",
                "# print(\"\\nEvaluation Results:\")\n",
                "# print(results_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualize System Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare performance of different methods\n",
                "# fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# # Plot MAE comparison\n",
                "# results_df['MAE'].plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
                "# axes[0].set_title('Mean Absolute Error Comparison')\n",
                "# axes[0].set_ylabel('MAE')\n",
                "# axes[0].set_xlabel('Method')\n",
                "# axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# # Plot RMSE comparison\n",
                "# results_df['RMSE'].plot(kind='bar', ax=axes[1], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
                "# axes[1].set_title('Root Mean Square Error Comparison')\n",
                "# axes[1].set_ylabel('RMSE')\n",
                "# axes[1].set_xlabel('Method')\n",
                "# axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "# plt.tight_layout()\n",
                "# plt.savefig('../plots/performance_comparison.png', dpi=300, bbox_inches='tight')\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Generate Final Recommendation Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive recommendation report\n",
                "# final_report = []\n",
                "\n",
                "# for user_id in target_users:\n",
                "#     user_report = {\n",
                "#         'user_id': user_id,\n",
                "#         'num_ratings': (user_item_matrix.loc[user_id] > 0).sum(),\n",
                "#         'avg_rating': user_item_matrix.loc[user_id].mean(),\n",
                "#         'top_collaborative_rec': all_recommendations[user_id]['collaborative'].iloc[0]['item_id'],\n",
                "#         'top_content_rec': all_recommendations[user_id]['content_based'].iloc[0]['item_id'],\n",
                "#         'top_hybrid_rec': all_recommendations[user_id]['hybrid'].iloc[0]['item_id']\n",
                "#     }\n",
                "#     final_report.append(user_report)\n",
                "\n",
                "# report_df = pd.DataFrame(final_report)\n",
                "# print(\"\\nFinal Recommendation Report:\")\n",
                "# print(report_df)\n",
                "\n",
                "# # Save report\n",
                "# report_df.to_csv('../results/final_recommendation_report.csv', index=False)\n",
                "# print(\"\\nReport saved to: ../results/final_recommendation_report.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary and Conclusions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"RECOMMENDER SYSTEM PIPELINE - SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(\"\\n1. Data Processing:\")\n",
                "# print(f\"   - Total users: {user_item_matrix.shape[0]}\")\n",
                "# print(f\"   - Total items: {user_item_matrix.shape[1]}\")\n",
                "# print(f\"   - Sparsity: {(user_item_matrix == 0).sum().sum() / user_item_matrix.size * 100:.2f}%\")\n",
                "\n",
                "print(\"\\n2. Methods Implemented:\")\n",
                "print(\"   ✓ Collaborative Filtering (User-based & Item-based)\")\n",
                "print(\"   ✓ Content-Based Filtering\")\n",
                "print(\"   ✓ Hybrid Recommender\")\n",
                "\n",
                "print(\"\\n3. Performance:\")\n",
                "# print(results_df)\n",
                "\n",
                "print(\"\\n4. Output Files:\")\n",
                "print(\"   - User-item matrix: results/user_item_matrix.csv\")\n",
                "print(\"   - Similarity matrices: results/\")\n",
                "print(\"   - Recommendations: results/final_recommendation_report.csv\")\n",
                "print(\"   - Plots: plots/performance_comparison.png\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"Pipeline execution complete!\")\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}